{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saved data load and use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below variables are established to be used throughout the notebook without being subjected to any change\n",
    "BATCH_SIZE     = 128\n",
    "HEIGHT = WIDTH = 48\n",
    "CHANNELS       =  3\n",
    "\n",
    "EMOTIONS       = ['surprise', 'fear', 'angry', 'neutral', 'sad', 'disgust', 'happy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import PIL.Image as Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as image\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the tensor back\n",
    "X_smote = np.load('X_smote.npy')\n",
    "y_smote = np.load('y_smote.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dropping 1 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12636, 6912)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_smote.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_filtered: [[ 46.  46.  46. ... 189. 189. 189.]\n",
      " [ 55.  55.  55. ... 187. 187. 187.]\n",
      " [123. 123. 123. ...   3.   3.   3.]\n",
      " ...\n",
      " [ 19.  19.  19. ...  50.  50.  50.]\n",
      " [166. 166. 166. ...  31.  31.  31.]\n",
      " [126. 126. 126. ...  98.  98.  98.]]\n",
      "y_filtered: [0 0 0 ... 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "# Find indices where y is not equal to 6\n",
    "indices_to_keep = y_smote != 6\n",
    "\n",
    "# Use boolean indexing to filter x and y\n",
    "X_smote = X_smote[indices_to_keep]\n",
    "y_smote = y_smote[indices_to_keep]\n",
    "\n",
    "# Print the filtered arrays\n",
    "print(\"x_filtered:\", X_smote)\n",
    "print(\"y_filtered:\", y_smote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12636])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# initializing label encoder\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "# convert X and y to Tensors\n",
    "x = torch.Tensor(X_smote) # features\n",
    "y_smote = label_encoder.fit_transform(y_smote) # targets\n",
    "y = torch.as_tensor(y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12636, 6912])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape of the X datasets along with y:\n",
      "    torch.Size([12636, 6912]), torch.Size([12636])\n",
      "\n",
      "Latest shape of the X datasets along with y:\n",
      "    torch.Size([12636, 3, 48, 48]), torch.Size([12636])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print initial shape of the datasets\n",
    "print(f\"Initial shape of the X datasets along with y:\\n\\\n",
    "    {x.shape}, {y.shape}\\n\")\n",
    "\n",
    "# reshape to remove the requirements of SMOTE that do not suit standard model training\n",
    "x = x.reshape((x.shape[0], 3, HEIGHT, WIDTH))\n",
    "\n",
    "# print latest shape of the datasets\n",
    "print(f\"Latest shape of the X datasets along with y:\\n\\\n",
    "    {x.shape}, {y.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, define the tasks according to class distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_id = [0 if i<2 else 1 if i<4 else 2 if i<6 else 3 for i in y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(tasks_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a transformation function to reshape your images, normalized and convert to tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add data transformations: (1) convert to tensor format, and (2) normalize the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=180),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create an Avalanche Tensor Dataset and a Scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from avalanche.benchmarks.scenarios import NCScenario\n",
    "# #from avalanche.models import ResNet50\n",
    "# from avalanche.training.plugins import EvaluationPlugin\n",
    "# from avalanche.benchmarks.utils import make_tensor_classification_dataset\n",
    "# #from avalanche.benchmarks.utils.data_loader import ContinuousScenarioDataLoader\n",
    "# from avalanche.training.supervised import Naive\n",
    "# from avalanche.evaluation.metrics import accuracy_metrics, loss_metrics, forgetting_metrics, disk_usage_metrics, cpu_usage_metrics, timing_metrics\n",
    "# from torch.optim import SGD\n",
    "# from avalanche.evaluation.metrics import forgetting_metrics, accuracy_metrics,\\\n",
    "#     loss_metrics, timing_metrics, cpu_usage_metrics, StreamConfusionMatrix,\\\n",
    "#     disk_usage_metrics, gpu_usage_metrics\n",
    "# from avalanche.models import SimpleMLP\n",
    "# from avalanche.logging import InteractiveLogger, TextLogger, TensorboardLogger\n",
    "# from avalanche.training.plugins import EvaluationPlugin\n",
    "# from avalanche.training import Naive, Replay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_trial, y_train, y_trial = train_test_split(x, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\TORCHGPU\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n",
      "d:\\anaconda\\envs\\TORCHGPU\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from avalanche.benchmarks.utils import make_tensor_classification_dataset\n",
    "trainds = make_tensor_classification_dataset(X_train, y_train)\n",
    "testds = make_tensor_classification_dataset(X_trial, y_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_FlatDataWithTransform (len=10108,subset=False,cat=False,cf=True)\n",
       "\t_TensorClassificationDataset (len=10108)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.benchmarks import nc_scenario\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.benchmarks.utils import make_tensor_classification_dataset\n",
    "from avalanche.training.supervised import Naive\n",
    "from avalanche.evaluation.metrics import accuracy_metrics, loss_metrics, forgetting_metrics, disk_usage_metrics, cpu_usage_metrics, timing_metrics\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into tasks\n",
    "nb_tasks = 3\n",
    "\n",
    "cl_scenario = nc_scenario(\n",
    "    train_dataset=trainds,\n",
    "    test_dataset=testds,\n",
    "    n_experiences=3,\n",
    "    task_labels=True,\n",
    "    seed=1234\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\TORCHGPU\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\anaconda\\envs\\TORCHGPU\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet50\n",
    "from torch.nn import Linear\n",
    "\n",
    "model = resnet50(pretrained=True)\n",
    "n_features = model.fc.in_features\n",
    "model.fc = Linear(n_features, 7)\n",
    "optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chossing the Naive strategy\n",
    "cl_strategy = Naive(\n",
    "    model,\n",
    "    optimizer,\n",
    "    torch.nn.CrossEntropyLoss(),\n",
    "    train_mb_size=500,\n",
    "    train_epochs=1,\n",
    "    eval_mb_size=100,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\TORCHGPU\\lib\\site-packages\\avalanche\\training\\plugins\\evaluation.py:94: UserWarning: No loggers specified, metrics will not be logged\n",
      "  warnings.warn(\"No loggers specified, metrics will not be logged\")\n"
     ]
    }
   ],
   "source": [
    "# Preparing a training plugin\n",
    "evaluation = EvaluationPlugin(\n",
    "    accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "    loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "    timing_metrics(epoch=True),\n",
    "    cpu_usage_metrics(experience=True),\n",
    "    timing_metrics(),\n",
    "    disk_usage_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "    forgetting_metrics(experience=True, stream=True),\n",
    ")\n",
    "\n",
    "# here we add a plugin to the strategy\n",
    "cl_strategy.evaluator = evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of experience:  0\n",
      "Current Classes:  [2, 3]\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 7/7 [00:35<00:00,  5.04s/it]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5226\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3396\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Computing accuracy on the whole test set\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 9/9 [00:18<00:00,  2.10s/it]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.8414\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.4814\n",
      "-- Starting eval on experience 1 (Task 1) from test stream --\n",
      "100%|██████████| 9/9 [00:13<00:00,  1.52s/it]\n",
      "> Eval on experience 1 (Task 1) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task001/Exp001 = 4.3603\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task001/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 2) from test stream --\n",
      "100%|██████████| 9/9 [00:13<00:00,  1.55s/it]\n",
      "> Eval on experience 2 (Task 2) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task002/Exp002 = 4.9117\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task002/Exp002 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task002 = 3.3547\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task002 = 0.1634\n",
      "Start of experience:  1\n",
      "Current Classes:  [4, 5]\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 7/7 [00:20<00:00,  2.98s/it]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task001 = 3.3076\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.0590\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Computing accuracy on the whole test set\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 9/9 [00:13<00:00,  1.47s/it]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.4170\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 1) from test stream --\n",
      "100%|██████████| 9/9 [00:12<00:00,  1.33s/it]\n",
      "> Eval on experience 1 (Task 1) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task001/Exp001 = 1.0276\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task001/Exp001 = 0.5217\n",
      "-- Starting eval on experience 2 (Task 2) from test stream --\n",
      "100%|██████████| 9/9 [00:12<00:00,  1.38s/it]\n",
      "> Eval on experience 2 (Task 2) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task002/Exp002 = 4.0314\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task002/Exp002 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task002 = 2.5270\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task002 = 0.1661\n",
      "Start of experience:  2\n",
      "Current Classes:  [0, 1]\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 7/7 [00:19<00:00,  2.77s/it]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task002 = 4.7715\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.0000\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Computing accuracy on the whole test set\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 9/9 [00:14<00:00,  1.60s/it]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 4.8573\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 1) from test stream --\n",
      "100%|██████████| 9/9 [00:12<00:00,  1.43s/it]\n",
      "> Eval on experience 1 (Task 1) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task001/Exp001 = 1.4732\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task001/Exp001 = 0.2174\n",
      "-- Starting eval on experience 2 (Task 2) from test stream --\n",
      "100%|██████████| 9/9 [00:14<00:00,  1.66s/it]\n",
      "> Eval on experience 2 (Task 2) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task002/Exp002 = 1.4283\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task002/Exp002 = 0.3387\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task002 = 2.6064\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task002 = 0.1851\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for experience in cl_scenario.train_stream:\n",
    "    print(\"Start of experience: \", experience.current_experience)\n",
    "    print(\"Current Classes: \", experience.classes_in_this_experience)\n",
    "\n",
    "    # train returns a dictionary which contains all the metric values\n",
    "    res = cl_strategy.train(experience, num_workers=4)\n",
    "    print('Training completed')\n",
    "\n",
    "    print('Computing accuracy on the whole test set')\n",
    "    # eval also returns a dictionary which contains all the metric values\n",
    "    results.append(cl_strategy.eval(cl_scenario.test_stream, num_workers=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
